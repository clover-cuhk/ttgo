{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: torch_batch_svd (https://github.com/KinglittleQ/torch-batch-svd) is not installed and is required for maximum efficiency of special_procrustes. Using torch.svd as a fallback.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(2, suppress=True)\n",
    "torch.set_printoptions(2, sci_mode=False)\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from panda_kinematics import PandaKinematics\n",
    "from ttgo import TTGO\n",
    "from manipulator_utils import exp_space, test_robotics_task\n",
    "from utils import Point2PointMotion, test_ttgo\n",
    "from panda_cost_utils import PandaCost,SDF_Cost \n",
    "device = \"cpu\" #torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")from motion_generation_utils import Point2PointMotion,Point2PointMotionCostFcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the environment (SDF and for graphics visualization in pybullet)\n",
    "import sys\n",
    "DATA_PATH = './data'\n",
    "body_sphere_path = './data/sphere_setting.npy'\n",
    "sdf_path = './data/sdf.npy'\n",
    "urdf_path = './data/urdf/frankaemika_new/panda_arm.urdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'panda-reach-mp-0-b-0.05-0.05-0.05-0.25-1.5-d0_theta-30-d0_w-30-nswp-30-rmax-100-kr-3.0-basis-rbf-margin-0.1-dt-0.1.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model and the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  0.25 0.25 0.25 0.0 0.25\n",
      "b:  0.05 0.05 0.05 1.5 0.25\n"
     ]
    }
   ],
   "source": [
    "# Load the parameters from the training\n",
    "model = torch.load(file_name,map_location=torch.device(\"cpu\"))\n",
    "tt_model = model['tt_model']\n",
    "w_goal,w_obst,w_orient, w_ee, w_control = model['w']\n",
    "b_goal,b_obst,b_orient, b_ee, b_control = model['b']\n",
    "\n",
    "print(\"w: \",w_goal,w_obst,w_orient, w_ee, w_control)\n",
    "print(\"b: \",b_goal,b_obst,b_orient, b_ee, b_control)\n",
    "\n",
    "d0_theta, d0_w = model['d0']\n",
    "K = model['K']\n",
    "margin= model['margin']\n",
    "domain, domain_task, domain_x_shelf, domain_x_box = model['domains']\n",
    "theta_0 = model['theta_0']\n",
    "theta_2 = model['theta_2']\n",
    "theta_3 = model['theta_3']\n",
    "dt = 0.01 #model['dt'] #\n",
    "basis = model['basis']\n",
    "Rd_0= model['Rd_0']\n",
    "v_d= model['v_d']\n",
    "mp = model['mp']\n",
    "test_task = model['test_task'] #torch.load('test_target.pickle')#\n",
    "key_points_weight = model['key_points_weight']\n",
    "key_points_margin = model['key_points_margin']\n",
    "panda = model['panda'];panda.set_device('cpu')\n",
    "p2p = model['p2p']; p2p.set_device('cpu')\n",
    "pandaCost = model['pandaCost']; pandaCost.set_device('cpu')\n",
    "sdf_cost = model['sdf_cost']; sdf_cost.set_device('cpu')\n",
    "\n",
    "theta_bounds = [panda.min_config, panda.max_config]\n",
    "p2p = Point2PointMotion(dt=dt, K=K, n=7, bounds=theta_bounds, basis=basis, device=device)\n",
    "pandaCost = PandaCost(p2p_motion=p2p,robot=panda, sdf_cost=sdf_cost, \n",
    "                    Rd_0=Rd_0, v_d=v_d,\n",
    "                    w_ee=w_ee, w_control=w_control, w_goal=w_goal, w_obst=w_obst, w_orient=w_orient,\n",
    "                    b_obst=b_obst,b_goal=b_goal,\n",
    "                    b_control=b_control, b_orient=b_orient, b_ee=b_ee,\n",
    "                    device=device)  \n",
    "\n",
    "\n",
    "data_sdf = np.load('./data/sdf.npy', allow_pickle=True)[()]\n",
    "sdf_matr = data_sdf['sdf_matr']  # SDF tensor\n",
    "bounds = torch.tensor(data_sdf['bounds']).to(device) # Bound of the environment\n",
    "env_bound = data_sdf['env_bound']  \n",
    "shelf_bound = data_sdf['shelf_bound'] \n",
    "box_bound = data_sdf['box_bound'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target reaching from a fixed initial configuration\n",
      "Discretization:  [60, 44, 17, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30]\n"
     ]
    }
   ],
   "source": [
    "if mp == 0: # target-reaching-from-fixed-initial-configuration\n",
    "    print(\"Target reaching from a fixed initial configuration\")\n",
    "    def cost_all(x):\n",
    "        return pandaCost.cost_j2p(x,theta_0)\n",
    "\n",
    "elif mp == 1: # via-point problem between fixed initial and final configurations\n",
    "    print(\"Via-point-1 problem between fixed initial and final configurations\")\n",
    "    def cost_all(x):\n",
    "        return pandaCost.cost_j2p2j(x, theta_0, theta_2)\n",
    "\n",
    "elif mp == 2: # fixed initial, given two target points to reach in sequence\n",
    "    print(\"Reach two target points in sequence\")\n",
    "    def cost_all(x):\n",
    "        return pandaCost.cost_j2p2p(x, theta_0)\n",
    "\n",
    "elif mp == 3: # fixed initial and , given two target points to reach in sequence\n",
    "    print(\"Via-point-2 problem between fixed initial and final configurations\")\n",
    "    def cost_all(x):\n",
    "        return pandaCost.cost_j2p2p2j(x, theta_0, theta_3)\n",
    "\n",
    "\n",
    "print(\"Discretization: \",[len(x) for x in domain])\n",
    "\n",
    "\n",
    "def cost(x):\n",
    "    return cost_all(x)[:,0]\n",
    "\n",
    "def pdf(x):\n",
    "    return torch.exp(-cost(x)**2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TT-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the TT-model\n",
    "ttgo = TTGO(domain=domain, pdf=pdf,cost=cost,device=device)\n",
    "ttgo.tt_model = tt_model\n",
    "ttgo.round(1e-6)\n",
    "ttgo.to('cpu')\n",
    "\n",
    "# Prepare for the task\n",
    "sites_task = list(range(3)) #list(range(len(domain_task)))\n",
    "ttgo.set_sites(sites_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites_task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generate test set for target point \n",
    "# ns = 50\n",
    "\n",
    "# ns_ = ns\n",
    "# test_x_1 = torch.zeros(ns_,3).to(device)\n",
    "# test_x_2 = torch.zeros(ns_,3).to(device)\n",
    "# for i in range(3):\n",
    "#     unif = torch.distributions.uniform.Uniform(low=domain_x_shelf[i][0],high=domain_x_shelf[i][-1])\n",
    "#     test_x_1[:,i]= torch.tensor([unif.sample() for i in range(ns_)]).to(device)\n",
    "#     unif = torch.distributions.uniform.Uniform(low=domain_x_box[i][0],high=domain_x_box[i][-1])\n",
    "#     test_x_2[:,i]= torch.tensor([unif.sample() for i in range(ns_)]).to(device)\n",
    "\n",
    "# # test_x_1  = test_x_1[(sdf_cost.sdf(test_x_1)-0.09)>0][:ns] # \n",
    "# # test_x_2  = test_x_2[(sdf_cost.sdf(test_x_2)-0.09)>0][:ns] # \n",
    "\n",
    "\n",
    "# if mp==0 or mp==1: \n",
    "#     test_task = test_x_1\n",
    "# if mp==2 or mp==3:\n",
    "#     test_task = torch.cat((test_x_1, test_x_2),dim=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm=1\n",
    "# print(\"total-cost | goal | collision | orientation | ee | control \")\n",
    "# # for alpha in [0.99,0.9,0.8,0.5]:\n",
    "# #     for n_samples_tt in [10,50,100,1000]:\n",
    "# #         _ = test_ttgo(ttgo=ttgo.clone(), cost=cost_all, \n",
    "# #             test_task=test_task, n_samples_tt=n_samples_tt,\n",
    "# #             alpha=alpha, norm=norm, device=device, test_rand=True)\n",
    "# alpha = 0.75; norm=1; n_samples_tt = 1000\n",
    "# costs_tt, costs_tt_opt, costs_rand, costs_rand_opt, tt_nit, rand_nit = test_ttgo(ttgo=ttgo.clone(), cost=cost_all, \n",
    "#             test_task=test_task, n_samples_tt=n_samples_tt,\n",
    "#             alpha=alpha, norm=norm, device=device, test_rand=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_batch = 10000\n",
    "# def cost_batched(x):\n",
    "#     ''' To avoid memorry issues with large batch processing in tt-cross, reduce computation into smaller batches '''   \n",
    "#     batch_size = x.shape[0]\n",
    "#     cost_values = torch.zeros(batch_size,cost_all(x[0].view(1,-1)).shape[1]).to(device)\n",
    "#     num_batch = batch_size//max_batch\n",
    "#     end_idx = 0\n",
    "#     for i in range(num_batch):\n",
    "#         start_idx = i*max_batch\n",
    "#         end_idx = (i+1)*max_batch\n",
    "#         cost_values[start_idx:end_idx,:] =cost_all(x[start_idx:end_idx])\n",
    "#     if batch_size>end_idx:          \n",
    "#         cost_values[end_idx:batch_size,:] = cost_all(x[end_idx:batch_size])\n",
    "#     return cost_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(test_task,\"test_target.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_set = [1,10,100,1000]\n",
    "# alphas = [0.9,0.75,0.5,0]\n",
    "# cut_total=0.25\n",
    "# with torch.no_grad():\n",
    "#     test_robotics_task(ttgo.clone(), cost_all, test_task, alphas, sample_set, cut_total,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybullet_data\n",
    "from panda_visualization_utils import *\n",
    "import pybullet as p\n",
    "from functools import partial\n",
    "\n",
    "p.connect(p.GUI)\n",
    "data = np.load(sdf_path, allow_pickle=True)[()]\n",
    "sdf_matr = data['sdf_matr']  #SDF tensor\n",
    "obstacles = data['obstacles'] #obstacles parameters\n",
    "colors = [[0.8, 0.5, 0.5, 1]]*len(obstacles)\n",
    "obj_id, init_id, target_id, border_id, obstacle_ids = init_pybullet (np.zeros(3), np.zeros(3), obstacles, colors=colors)\n",
    "p.setPhysicsEngineParameter(enableFileCaching=0)\n",
    "p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "p.configureDebugVisualizer(p.COV_ENABLE_GUI,0)\n",
    "robot_urdf ='./data/urdf/frankaemika_new/panda_arm.urdf'\n",
    "robot_id = p.loadURDF(fileName=robot_urdf)\n",
    "dof = p.getNumJoints(robot_id)\n",
    "pb_joint_indices = np.arange(7)\n",
    "joint_limits = get_joint_limits(robot_id,pb_joint_indices)\n",
    "mean_pose = 0.5*(joint_limits[0]+joint_limits[1])\n",
    "set_q_std = partial(set_q,robot_id, pb_joint_indices)\n",
    "rmodel = pin.buildModelFromUrdf(robot_urdf)\n",
    "rdata = rmodel.createData()\n",
    "pin_frame_names = [f.name for f in rmodel.frames]\n",
    "ee_frame_id = rmodel.getFrameId('panda_hand_joint')\n",
    "alpha = np.deg2rad(52)\n",
    "quat = p.getQuaternionFromAxisAngle((0,0,1),alpha)\n",
    "p.resetBasePositionAndOrientation(robot_id, (0,0,0.05), quat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a random task find the decision variables (multiple solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.60,  0.34,  0.09])\n",
      "Time taken: 1.8695852756500244 1.0888481140136719\n",
      "Cost-mean-tt: tensor([    0.36,     0.00,     0.00,     0.04,     3.65,     0.16])\n",
      "Cost-mean-rand: tensor([    0.72,     0.02,     0.00,     0.01,     3.15,     0.53])\n"
     ]
    }
   ],
   "source": [
    "s = np.random.randint(0,test_task.shape[0]-1)\n",
    "sample_xe = test_task[s][:3]\n",
    "sample_xe[0] = -0.6\n",
    "# sample_xe[:3]= torch.tensor([-0.55,0.2,0.15])\n",
    "# sample_xe[0]=-0.7; sample_xe[2]=0.1; sample_xe[5]=0.3; sample_xe[4]=0.65; sample_xe[3]=-0.15\n",
    "# sample_xe[:3] = torch.tensor([0.55, 0.5, 0.75])\n",
    "#torch.tensor([0.6, 0.4, 0.45]) #center center\n",
    "#test_task[s]#torch.tensor([ 0.66,  0.16,  0.40, -0.17,  0.55,  0.32]) #torch.tensor([0.6, 0.47, 0.75, -0.25,  0.61,  0.35])#test_task[s]\n",
    "# torch.tensor([ 0.66,  0.16,  0.40, -0.17,  0.55,  0.32]) # \n",
    "# tensor([ 0.66,  0.16,  0.40, -0.17,  0.55,  0.32])\n",
    "# torch.tensor([0.54, 0.63, 0.12])\n",
    "#torch.tensor([0.70, 0.40, 0.15])#\n",
    "print(sample_xe)\n",
    "# torch.tensor([0.55, 0.4347, 0.4]) # middle center\n",
    "# torch.tensor([0.4435, 0.4347, 50.2139]) # bottom center\n",
    "# torch.tensor([0.4991, 0.6301, 0.3695]) # bottom left\n",
    "# torch.tensor([0.6352, 0.4708, 0.7535]) # top left\n",
    "# torch.tensor([0.6789, 0.1950, 0.6976]) # top shelf center\n",
    "# torch.tensor([0.6635, 0.6250, 0.2031]) # bottom, in, inaccessible\n",
    "# tirch.tensor([0.4228, 0.4441, 0.8760]) # top \n",
    "# sample_xe = torch.tensor([0.8, -0.1, 0.3]) #torch.tensor([0.8, -0.3, 0.35])#torch.torch.tensor([ 0.6404, 0.2350,  0.549])#torch.tensor([ 0.7130, -0.3007, -0.1276]) #\n",
    "n_solutions= 3\n",
    "n_samples_tt = 1000\n",
    "n_samples_rand= n_samples_tt\n",
    "\n",
    "alpha=0.85; norm=1 ;\n",
    "\n",
    "t1 = time.time()\n",
    "samples_tt, samples_idx = ttgo.sample(n_samples=n_samples_tt, x_task=sample_xe.reshape(1,-1),alpha=alpha,norm=norm)\n",
    "state_k_tt = ttgo.choose_top_k_sample(samples_tt,n_solutions)\n",
    "t2=time.time()\n",
    "\n",
    "#Optimize\n",
    "state_k_tt_opt = 1*state_k_tt\n",
    "for i, state in enumerate(state_k_tt):\n",
    "    state_k_tt_opt[i,:],results= ttgo.optimize(state,bound=True)\n",
    "t3 = time.time()\n",
    "samples_rand, _ = ttgo.sample_random(n_samples=n_samples_rand,  x_task=sample_xe.reshape(1,-1))\n",
    "state_k_rand = ttgo.choose_top_k_sample(samples_rand,n_solutions)\n",
    "t4=time.time()\n",
    "\n",
    "# #Optimize\n",
    "state_k_rand_opt = state_k_rand*1\n",
    "for i, state in enumerate(state_k_rand):\n",
    "    state_k_rand_opt[i,:],results= ttgo.optimize(state,bound=True)\n",
    "t5=time.time()\n",
    "\n",
    "print(\"Time taken:\", (t2-t1), t4-t3)\n",
    "             \n",
    "c_tt =  cost_all(state_k_tt_opt)\n",
    "c_rand =   cost_all(state_k_rand_opt)\n",
    "\n",
    "print(\"Cost-mean-tt:\",torch.mean(c_tt,dim=0))\n",
    "print(\"Cost-mean-rand:\",torch.mean(c_rand,dim=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the decision variables construct the joint angle trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costs:  tensor([0.00, 0.00, 0.74])\n"
     ]
    }
   ],
   "source": [
    "n_joints=7\n",
    "theta_bounds = [panda.min_config, panda.max_config]\n",
    "p2p_ =Point2PointMotion(dt=0.001, K=K, n=n_joints,bounds=theta_bounds, basis=basis, device=device)\n",
    "\n",
    "x = 1*state_k_tt_opt\n",
    "if mp==0:\n",
    "    xgoal_1 = x[:,:3] # of the end-effector: batch x positions\n",
    "    theta_1 = x[:,3:3+n_joints] # final configuration, batch x joint-angles\n",
    "    w = x[:,3+n_joints:] # basis weights\n",
    "    theta_t = p2p_.gen_traj_p2p(theta_0.repeat(n_solutions,1),theta_1,w) # batch x time x joint \n",
    "\n",
    "elif mp==1:\n",
    "    xgoal_1 = x[:,:3] # via-point\n",
    "    theta_1 = x[:,3:3+n_joints] # via-configuration\n",
    "    w01 = x[:,3+n_joints:3+n_joints+n_joints*K] # basis weights for phase 1 (theta_0 to theta_1)\n",
    "    w12 = x[:,3+n_joints+n_joints*K:] # basis weights for phase 2 (theta_1 to theta_2)\n",
    "    # joint-angle traj from initial config to via config        \n",
    "    theta_01_t = p2p_.gen_traj_p2p(theta_0.repeat(n_solutions,1),theta_1,w01) #batch x time/2 x joint\n",
    "    # joint-angle traj from via-config to final config\n",
    "    theta_12_t = p2p_.gen_traj_p2p(theta_1,theta_2.repeat(n_solutions,1),w12) #batch x time/2 x joint\n",
    "    T01 = theta_01_t.shape[1]\n",
    "    T12 = theta_12_t.shape[1]\n",
    "\n",
    "elif mp==2:\n",
    "    xgoal_1 = x[:,:3] # via-point-1\n",
    "    x_goal_2 = x[:,3:6] # via-point-2\n",
    "    theta_1 = x[:,6:6+n_joints] # via-configuration-1\n",
    "    theta_2 = x[:,6+n_joints:6+2*n_joints] # via-configuration-1\n",
    "    w01 = x[:,6+2*n_joints:6+2*n_joints+n_joints*K] # basis weights for phase 1 (theta_0 to theta_1)\n",
    "    w12 = x[:,6+2*n_joints+n_joints*K:] # basis weights for phase 2 (theta_1 to theta_2)\n",
    "    # joint-angle traj from initial config to via config        \n",
    "    theta_01_t = p2p_.gen_traj_p2p(theta_0.repeat(n_solutions,1),theta_1,w01) #batch x time/2 x joint\n",
    "    # joint-angle traj from via-config-1 to via-config-2 (final config)\n",
    "    theta_12_t = p2p_.gen_traj_p2p(theta_1,theta_2,w12) #batch x time/2 x joint\n",
    "    T01 = theta_01_t.shape[1]\n",
    "    T12 = theta_12_t.shape[1]\n",
    "    \n",
    "elif mp==3:\n",
    "    xgoal_1 = x[:,:3] # via-point-1\n",
    "    x_goal_2 = x[:,3:6] # via-point-2\n",
    "    theta_1 = x[:,6:6+n_joints] # via-configuration-1\n",
    "    theta_2 = x[:,6+n_joints:6+2*n_joints] # via-configuration-1\n",
    "    w01 = x[:,6+2*n_joints:6+2*n_joints+n_joints*K] # basis weights for phase 1 (theta_0 to theta_1)\n",
    "    w12 = x[:,6+2*n_joints+n_joints*K:6+2*n_joints+2*n_joints*K] # basis weights for phase 2 (theta_1 to theta_2)\n",
    "    w23 = x[:,6+2*n_joints+2*n_joints*K:]\n",
    "    # joint-angle traj from initial config to via config        \n",
    "    theta_01_t = p2p_.gen_traj_p2p(theta_0.repeat(n_solutions,1),theta_1,w01) #batch x time/2 x joint\n",
    "    # joint-angle traj from via-config-1 to via-config-2\n",
    "    theta_12_t = p2p_.gen_traj_p2p(theta_1,theta_2,w12) #batch x time/2 x joint\n",
    "    # joint-angle traj from via-config-1 to via-config-2\n",
    "    theta_23_t = p2p_.gen_traj_p2p(theta_2,theta_3.repeat(n_solutions,1),w23) #batch x time/2 x joint\n",
    "    T01 = theta_01_t.shape[1]\n",
    "    T12 = theta_12_t.shape[1]\n",
    "    T23 = theta_23_t.shape[1]\n",
    "    theta_t = torch.cat((theta_01_t,theta_12_t,theta_23_t),dim=1)\n",
    "\n",
    "    \n",
    "costs_ = cost(x)\n",
    "print(\"Costs: \", costs_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Joint Violate: \", torch.sum(theta_t < panda.theta_min_robot) + torch.sum(theta_t > panda.theta_max_robot) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ , _,sphere_id = create_primitives(p.GEOM_SPHERE, radius = 0.02)\n",
    "pos = x[0,:3]\n",
    "p.resetBasePositionAndOrientation(sphere_id, pos, (0,0,0,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mp>1:\n",
    "    _ , _,sphere_id = create_primitives(p.GEOM_SPHERE, radius = 0.02)\n",
    "    pos = x[0,3:6];\n",
    "    p.resetBasePositionAndOrientation(sphere_id, pos, (0,0,0,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the joint angle trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)\n",
    "dt = 0.01\n",
    "if mp==0:\n",
    "    for k_ in range(n_solutions):\n",
    "        set_q_std(theta_t[0,0,:])\n",
    "        T = theta_t.shape[1]\n",
    "        time.sleep(30*dt)\n",
    "        for t in range(T):\n",
    "            set_q_std(theta_t[k_,t,:])\n",
    "            time.sleep(1*dt)\n",
    "        time.sleep(10*dt)\n",
    "elif mp==1 or mp==2:\n",
    "    for k_ in range(n_solutions):\n",
    "        set_q_std(theta_01_t[0,0,:])\n",
    "        time.sleep(2)\n",
    "        for t in range(T01):\n",
    "            set_q_std(theta_01_t[k_,t,:])\n",
    "            time.sleep(1*dt)\n",
    "        time.sleep(1)\n",
    "        for t in range(T12):\n",
    "            set_q_std(theta_12_t[k_,t,:])\n",
    "            time.sleep(1*dt)\n",
    "        time.sleep(2)\n",
    "elif mp==3:\n",
    "    for k_ in range(n_solutions):\n",
    "        set_q_std(theta_01_t[0,0,:])\n",
    "        time.sleep(2)\n",
    "        for t in range(T01):\n",
    "            set_q_std(theta_01_t[k_,t,:])\n",
    "            time.sleep(1*dt)\n",
    "        time.sleep(1)\n",
    "        for t in range(T12):\n",
    "            set_q_std(theta_12_t[k_,t,:])\n",
    "            time.sleep(1*dt)\n",
    "        time.sleep(1)\n",
    "        for t in range(T23):\n",
    "            set_q_std(theta_23_t[k_,t,:])\n",
    "            time.sleep(1*dt)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(theta_t,'reach_10.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
